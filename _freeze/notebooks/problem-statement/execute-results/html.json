{
  "hash": "d047c930e6de655119a7c4ab6eec0e0f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A Study on Automatic Turning of Denoising Algorithm Parameters in Medical Images\"\nauthor:\n  - name: Siju K S\n    affiliation: \n      - Research Scholar\n      - Center for Computational Engineering & Networking\n      - Amrita Vishwa Vidyapeetham\nnumber-sections: true\njupyter: python3\nbibliography: references.bib\n---\n\n\n# Problem Statement for the Research Work\n\nNoise presents a major barrier to accurate interpretation in medical imaging, particularly in resource-limited healthcare environments where access to advanced, noise-resistant imaging technologies remains restricted. Despite the efficiency of modern high-resolution imaging systems like MRI and CT in reducing noise, their high cost and limited availability prevent widespread implementation, especially in public health infrastructures. Thus, enhancing the diagnostic quality of existing imaging modalities via advanced denoising methods is both an essential and sustainable solution for improving global healthcare.\n\nConventional denoising algorithms [@dogra2018survey], especially deep learning-based approaches, often rely on the availability of clean, noise-free reference images for training [@9210208]. In medical imaging, such ground-truth data is rarely available, complicating efforts to denoise noisy medical scans effectively. Recent research has explored automated approaches to optimize denoising parameters. For instance, Zhu and Milanfar [@5484579] developed a no-reference measure for automatic parameter selection, while Ramani et al. [@4598837] proposed Monte-Carlo optimization for regularization parameters. Although recent works—such as `Noise2Noise`, `Noisier2Noise`, and `Recorrupted-to-Recorrupted`—have demonstrated success in learning from noisy data without clean references, they remain largely constrained to synthetic and general-purpose image datasets with training phases ([@lehtinen2018noise2noise]; [@9156650]; [@9577798]). The complexity and specificity of medical image noise, often non-linear in nature, present challenges these methods are ill-equipped to handle.\n\nIn their recent work, Floquet et al.[@floquet:hal-04344047] introduced an automatic tuning mechanism for denoising algorithms that circumvents the need for ground-truth images, employing Mean Squared Error (MSE) as the loss function and optimizing through gradient descent. While this approach has demonstrated effectiveness on datasets such as BSD400, particularly in linear noise scenarios, its gradient-based optimization framework faces challenges when applied to non-linear noise models, which are prevalent in medical images.\n\nBuilding on this foundation, we propose to extend Floquet et al.'s framework to tackle non-linear noise by incorporating nature-inspired optimization methods—such as genetic algorithms and particle swarm optimization. These techniques are well-suited for complex, non-linear optimization landscapes, overcoming the limitations posed by gradient descent. Our approach aims to enhance the robustness of denoising algorithms, particularly in the context of medical imaging, where noise is often more intricate, and ground-truth clean images are typically unavailable. This advancement holds potential not only for improved diagnostic accuracy but also for making high-quality medical imaging more accessible in resource-constrained healthcare environments, aligning with broader goals of sustainability and equity in global health systems.\n\n\n\n# References\n\n::: {#refs}\n:::\n\n",
    "supporting": [
      "problem-statement_files"
    ],
    "filters": [],
    "includes": {}
  }
}